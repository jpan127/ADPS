{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import images\n",
    "image_list = []\n",
    "image_data = []\n",
    "for filename in glob.glob('Sidewalk/*.JPG'):\n",
    "    im=Image.open(filename)\n",
    "    imcv=cv2.imread(filename)\n",
    "    image_list.append(imcv)\n",
    "    image_data.append(list(im.getdata()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# color regions\n",
    "HSV_data = []\n",
    "for image in image_list:\n",
    "    HSV = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    HSV_data.append(HSV)\n",
    "#     HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "#     GRAY = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     cv2.imshow(\"Images\", np.hstack([HSV, HLS]))\n",
    "#     cv2.imshow(\"Original\", image)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV would be helpful for distinguishing between the road, sidewalk, and other areas, so we'll continue with that when it comes to making a mask.\n",
    "\n",
    "Let's continue by blurring the image to see if that helps define the lines between the road and sidewalk. Almost seems counterintuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median_data = []\n",
    "\n",
    "for image in image_list:\n",
    "    BLUR = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    MEDIAN = cv2.medianBlur(image,5)\n",
    "#     MEDIAN = cv2.medianBlur(MEDIAN,5)\n",
    "    median_data.append(MEDIAN)\n",
    "#     cv2.imshow(\"Blurred\", BLUR)\n",
    "#     cv2.imshow(\"Median\", MEDIAN)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blurring the image seems to do the trick. It keeps the colors the same while reducing noise. This lets us eliminate the moss on the sidewalk and keeps the lines remain well defined.\n",
    "\n",
    "One possible problem would be a clean sidewalk with the sun directly overhead. This would result in the sidewalk lines dissapearing. The road-sidewalk distinction would remain the same.\n",
    "\n",
    "At this point we've got our data. Let's try gray scale on this to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for image in median_data:\n",
    "#     GRAY = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     cv2.imshow(\"GRAY\", GRAY)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much unfortunately. At this point, let's try eliminating all non gray colors.\n",
    "\n",
    "First begin by defining the range of colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_sidewalk(image):\n",
    "    # sidewalk color mask using HSV scale\n",
    "    lower = np.uint8([  0, 0,   140])\n",
    "    upper = np.uint8([179, 60, 200])\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "    return cv2.bitwise_and(image, image, mask = mask)\n",
    "\n",
    "def select_sidewalk_dynamically(image):\n",
    "    # Get ROI:\n",
    "    height, width, channels = image.shape\n",
    "    ROI = [height-100, height, round((width/2)-80), round((width/2)+80)]\n",
    "    im1 = image[ROI[0]:ROI[1], ROI[2]:ROI[3]]\n",
    "    # Determine color range\n",
    "    lower = np.array([im1[:,:,0].min(), im1[:,:,1].min(), im1[:,:,2].min()])\n",
    "    upper = np.array([im1[:,:,0].max(), im1[:,:,1].max(), im1[:,:,2].max()])\n",
    "    # sidewalk color mask using HSV scale\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "    mask2 = cv2.inRange(image, lower, upper)\n",
    "    return cv2.bitwise_and(image, image, mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and test it out on a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask_test = select_sidewalk(HSV_data[0])\n",
    "# cv2.imshow(\"MASK\", mask_test)\n",
    "# cv2.imshow(\"HSV\", HSV_data[0])\n",
    "# cv2.imshow(\"Original\", image_list[0])\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears to work! But there are some gaps where the sidewalk is dirty, or it's too far and increases in saturation (warmth at vanishing points something something).\n",
    "\n",
    "So let's go ahead and use the blurred image, change the color space, and apply the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# masked_images = []\n",
    "\n",
    "# for image in median_data:\n",
    "#     mask_test = select_sidewalk(cv2.cvtColor(image, cv2.COLOR_RGB2HSV))\n",
    "#     masked_images.append(mask_test)\n",
    "#     cv2.imshow(\"MASK\", mask_test)\n",
    "#     cv2.imshow(\"Blurred\", image)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks great. The sidewalk and road are selected, with more of the sidewalk being selected than the road. Let's do this dynamically by selecting a ROI (region of interest) in the bottom-middle of the image. We'll extract the color ranges and then interpolate an HSV color range for the filter.\n",
    "\n",
    "First up, capturing the ROI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# height, width, channels = median_data[0].shape\n",
    "# ROI = [height-100, height, round((width/2)-80), round((width/2)+80)]\n",
    "# im1 = median_data[0][ROI[0]:ROI[1], ROI[2]:ROI[3]]\n",
    "# cv2.imshow(\"CROP\", im1)\n",
    "# cv2.imshow(\"Blurred\", median_data[0])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# print(height, width, channels)\n",
    "# print(ROI[0], ROI[1], ROI[2], ROI[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's determine the HSV color ranges using a rudimentary min/max function on the color ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lower = np.array([im1[:,:,0].min(), im1[:,:,1].min(), im1[:,:,2].min()])\n",
    "# upper = np.array([im1[:,:,0].max(), im1[:,:,1].max(), im1[:,:,2].max()])\n",
    "# print(lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now test it to filter the blurred sidewalk image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for image in median_data:\n",
    "#     mask_test = select_sidewalk_dynamically(cv2.cvtColor(image, cv2.COLOR_RGB2HSV))\n",
    "#     masked_images.append(mask_test)\n",
    "#     cv2.imshow(\"MASK\", mask_test)\n",
    "#     cv2.imshow(\"Blurred\", image)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely an improvement, but there are some issues...\n",
    "\n",
    "1. If there's some debris in the ROI, it's anyones guess what's going to be selected.\n",
    "    1. Debris can be grass, leaves, anything.\n",
    "2. If the ROI is not directly on the sidewalk something else is going to be selected.\n",
    "    1. An example of this would be a curve, or a tree planted on the sidewalk.\n",
    "    2. In such a scenario a larger color range is allowed.\n",
    "\n",
    "Solutions are needed for each issue.\n",
    "\n",
    "1. Use statistics to eliminate the debris. A leaf or debris will show up as an outlier in the image dataset, and can be eliminated. Currently, only min/max is being used. That's a rudimentary algorithm at best.\n",
    "2. Use legacy data, or train the robot to only search for specific colors.\n",
    "    1. We don't want to travel on dirt, so don't look for brown.\n",
    "    2. Same for grass.\n",
    "    3. Possibly make the algorithm more robust by allowing specific colors for initial detection, then extend once a possible path has been found.\n",
    "    \n",
    "For now, let's try to apply edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_fill(im_in):\n",
    "    # Threshold.\n",
    "    # Set values equal to or above 220 to 0.\n",
    "    # Set values below 220 to 255.\n",
    "    th, im_th = cv2.threshold(im_in, 0, 255, cv2.THRESH_BINARY);\n",
    "\n",
    "    # Copy the thresholded image.\n",
    "    im_floodfill = im_th.copy()\n",
    "\n",
    "    # Mask used to flood filling.\n",
    "    # Notice the size needs to be 2 pixels than the image.\n",
    "    h, w = im_th.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    # Floodfill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    "\n",
    "    # Invert floodfilled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "\n",
    "    # Combine the two images to get the foreground.\n",
    "    im_out = im_th | im_floodfill_inv\n",
    "    return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernel_size=5\n",
    "# for image in median_data:\n",
    "#     original_image = image\n",
    "#     image = select_sidewalk_dynamically(cv2.cvtColor(image, cv2.COLOR_RGB2HSV))\n",
    "#     image = cv2.medianBlur(image,5)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "#     binarized = color_fill(image)\n",
    "#     edges = cv2.Canny(image,50,150,apertureSize = 3)\n",
    "#     lines = cv2.HoughLinesP(edges,1,np.pi/180,85,150)\n",
    "    \n",
    "#     # displays line segments\n",
    "#     a,b,c = lines.shape\n",
    "#     for i in range(a):\n",
    "#         cv2.line(binarized, (lines[i][0][0], lines[i][0][1]), (lines[i][0][2], lines[i][0][3]), (0, 0, 255), 3, cv2.LINE_AA)\n",
    "    \n",
    "#     lines = cv2.HoughLines(edges,1,np.pi/180,75,150)\n",
    "#     a,b,c = lines.shape\n",
    "#     for i in range(a):\n",
    "#         rho = lines[i][0][0]\n",
    "#         theta = lines[i][0][1]\n",
    "#         a = math.cos(theta)\n",
    "#         b = math.sin(theta)\n",
    "#         x0, y0 = a*rho, b*rho\n",
    "#         pt1 = ( int(x0+1000*(-b)), int(y0+1000*(a)) )\n",
    "#         pt2 = ( int(x0-1000*(-b)), int(y0-1000*(a)) )\n",
    "#         cv2.line(image, pt1, pt2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "#     cv2.imshow(\"Original\", original_image)        \n",
    "#     cv2.imshow(\"Lines\", image)\n",
    "#     cv2.imshow(\"Binarized\", binarized)\n",
    "#     cv2.imshow(\"im1\", edges)\n",
    "# #     cv2.imshow(\"im2\", im2)\n",
    "# #     cv2.imshow(\"im3\", im3)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/SZanlongo/vanishing-point-detection/blob/master/src/VanishingPoint.py\n",
    "\n",
    "# Perform edge detection\n",
    "def hough_transform(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert image to grayscale\n",
    "\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    opening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)  # Open (erode, then dilate)\n",
    "    # cv2.imwrite('../pictures/output/opening.jpg', opening)\n",
    "\n",
    "    edges = cv2.Canny(opening, 50, 150, apertureSize=3)  # Canny edge detection\n",
    "\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,75,150)\n",
    "    hough_lines = []\n",
    "  \n",
    "    a,b,c = lines.shape\n",
    "    for i in range(a):\n",
    "        rho = lines[i][0][0]\n",
    "        theta = lines[i][0][1]\n",
    "        a = math.cos(theta)\n",
    "        b = math.sin(theta)\n",
    "        x0, y0 = a*rho, b*rho\n",
    "        pt1 = ( int(x0+1000*(-b)), int(y0+1000*(a)) )\n",
    "        pt2 = ( int(x0-1000*(-b)), int(y0-1000*(a)) )\n",
    "        cv2.line(image, pt1, pt2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        hough_lines.append((pt1, pt2))\n",
    "    \n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)  # Hough line detection\n",
    "    return hough_lines\n",
    "\n",
    "\n",
    "# Random sampling of lines\n",
    "def sample_lines(lines, size):\n",
    "    if size > len(lines):\n",
    "        size = len(lines)\n",
    "    return random.sample(lines, size)\n",
    "\n",
    "\n",
    "def det(a, b):\n",
    "    return a[0] * b[1] - a[1] * b[0]\n",
    "\n",
    "\n",
    "# Find intersection point of two lines (not segments!)\n",
    "def line_intersection(line1, line2):\n",
    "    x_diff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0])\n",
    "    y_diff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1])\n",
    "\n",
    "    div = det(x_diff, y_diff)\n",
    "    if div == 0:\n",
    "        return None  # Lines don't cross\n",
    "\n",
    "    d = (det(*line1), det(*line2))\n",
    "    x = det(d, x_diff) / div\n",
    "    y = det(d, y_diff) / div\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Find intersections between multiple lines (not line segments!)\n",
    "def find_intersections(lines, img):\n",
    "    intersections = []\n",
    "    for i in range(len(lines)):\n",
    "        line1 = lines[i]\n",
    "        for j in range(i + 1, len(lines)):\n",
    "            line2 = lines[j]\n",
    "\n",
    "            if not line1 == line2:\n",
    "                intersection = line_intersection(line1, line2)\n",
    "                if intersection:  # If lines cross, then add\n",
    "                    # Don't include intersections that happen off-image\n",
    "                    # Seems to cost more time than it saves\n",
    "                    # if not (intersection[0] < 0 or intersection[0] > img.shape[1] or\n",
    "                    #                 intersection[1] < 0 or intersection[1] > img.shape[0]):\n",
    "                    # print 'adding', intersection[0],intersection[1],img.shape[1],img.shape[0]\n",
    "                    intersections.append(intersection)\n",
    "\n",
    "    return intersections\n",
    "\n",
    "\n",
    "# Given intersections, find the grid where most intersections occur and treat as vanishing point\n",
    "def find_vanishing_point(img, grid_size, intersections):\n",
    "    # Image dimensions\n",
    "    image_height = img.shape[0]\n",
    "    image_width = img.shape[1]\n",
    "\n",
    "    # Grid dimensions\n",
    "    grid_rows = (image_height // grid_size) + 1\n",
    "    grid_columns = (image_width // grid_size) + 1\n",
    "\n",
    "    # Current cell with most intersection points\n",
    "    max_intersections = 0\n",
    "    best_cell = None\n",
    "\n",
    "    for i in range(grid_rows):\n",
    "        for j in range(grid_columns):\n",
    "            cell_left = i * grid_size\n",
    "            cell_right = (i + 1) * grid_size\n",
    "            cell_bottom = j * grid_size\n",
    "            cell_top = (j + 1) * grid_size\n",
    "            cv2.rectangle(img, (cell_left, cell_bottom), (cell_right, cell_top), (0, 0, 255), 10)\n",
    "\n",
    "            current_intersections = 0  # Number of intersections in the current cell\n",
    "            for x, y in intersections:\n",
    "                if cell_left < x < cell_right and cell_bottom < y < cell_top:\n",
    "                    current_intersections += 1\n",
    "\n",
    "            # Current cell has more intersections that previous cell (better)\n",
    "            if current_intersections > max_intersections:\n",
    "                max_intersections = current_intersections\n",
    "                best_cell = ((cell_left + cell_right) / 2, (cell_bottom + cell_top) / 2)\n",
    "\n",
    "    if not best_cell == [None, None]:\n",
    "        rx1 = best_cell[0] - grid_size / 2\n",
    "        ry1 = best_cell[1] - grid_size / 2\n",
    "        rx2 = best_cell[0] + grid_size / 2\n",
    "        ry2 = best_cell[1] + grid_size / 2\n",
    "        cv2.rectangle(img, ( int(rx1), int(ry1)), (int(rx2), int(ry2)), (0, 255, 0), 10)\n",
    "        # cv2.imwrite('../pictures/output/center.jpg', img)\n",
    "\n",
    "    return best_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/SZanlongo/vanishing-point-detection/blob/master/src/Testing.py\n",
    "for img in median_data:\n",
    "    hough_lines = hough_transform(img)\n",
    "    if hough_lines:\n",
    "        random_sample = sample_lines(hough_lines, 100)\n",
    "        intersections = find_intersections(random_sample, img)\n",
    "        if intersections:\n",
    "            grid_size = min(img.shape[0], img.shape[1]) // 10\n",
    "            vanishing_point = find_vanishing_point(img, grid_size, intersections)\n",
    "            cv2.imshow(\"Image\", img)\n",
    "            cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
